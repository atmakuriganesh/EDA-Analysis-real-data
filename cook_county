import os
import pandas as pd
import re
import glob

def process_salary_files(folder_path, file_list):
    """
    Process salary files from a folder based on a list of files.
    Scans all sheets in each file automatically.
    
    Args:
        folder_path (str): Path to the folder containing CSV/Excel files
        file_list (list): List of filenames to process
    
    Returns:
        pandas.DataFrame: Combined data with required columns
    """
    all_data = []
    
    for file_name in file_list:
        file_path = os.path.join(folder_path, file_name)
        
        # Determine the file extension
        file_ext = os.path.splitext(file_path)[1].lower()
        
        try:
            # For CSV files
            if file_ext == '.csv':
                df = pd.read_csv(file_path)
                processed_df = process_dataframe(df, file_name)
                if processed_df is not None:
                    all_data.append(processed_df)
            
            # For Excel files - try different engines
            elif file_ext in ['.xlsx', '.xls']:
                # Try different engines for Excel files
                engines = ['openpyxl', 'xlrd']
                success = False
                
                for engine in engines:
                    try:
                        if file_ext == '.xls' and engine == 'openpyxl':
                            # Skip openpyxl for .xls files
                            continue
                            
                        print(f"Trying to read {file_name} with {engine} engine...")
                        
                        # Get all sheet names
                        excel_file = pd.ExcelFile(file_path, engine=engine)
                        sheet_names = excel_file.sheet_names
                        
                        for sheet_name in sheet_names:
                            try:
                                df = pd.read_excel(file_path, sheet_name=sheet_name, engine=engine)
                                processed_df = process_dataframe(df, f"{file_name}_{sheet_name}")
                                if processed_df is not None:
                                    all_data.append(processed_df)
                            except Exception as sheet_e:
                                print(f"Error processing sheet {sheet_name} in {file_name}: {str(sheet_e)}")
                        
                        # If we get here without errors, we've processed the file
                        success = True
                        break
                        
                    except Exception as engine_e:
                        print(f"Engine {engine} failed for {file_name}: {str(engine_e)}")
                
                if not success:
                    print(f"Failed to process {file_name} with all available engines")
            else:
                print(f"Unsupported file format for {file_name}")
                continue
                
        except Exception as e:
            print(f"Error processing {file_name}: {str(e)}")
    
    # Combine all data
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # Aggregate by grade and category to get min and max rates
        aggregated_df = combined_df.groupby(['grade', 'category']).agg({
            'start_rate': 'min',
            'end_rate': 'max'
        }).reset_index()
        
        # Add term column with value 'annual'
        aggregated_df['term'] = 'annual'
        
        # Reorder columns
        aggregated_df = aggregated_df[['grade', 'term', 'start_rate', 'end_rate', 'category']]
        
        return aggregated_df
    else:
        return pd.DataFrame(columns=['grade', 'term', 'start_rate', 'end_rate', 'category'])

def process_dataframe(df, file_name):
    """
    Process a single dataframe to extract the required information.
    
    Args:
        df (pandas.DataFrame): The dataframe to process
        file_name (str): Name of the file/sheet for category
    
    Returns:
        pandas.DataFrame: Processed dataframe with required columns
    """
    # Make a copy of the dataframe to avoid modifying the original
    df_copy = df.copy()
    
    # Convert all values to string for easier searching
    for col in df_copy.columns:
        df_copy[col] = df_copy[col].astype(str)
    
    # Find the starting row where "GRADE" appears
    start_row = None
    grade_col_idx = None
    
    # Search for any mention of "GRADE" or "JOB CODE" in each row
    for i, row in df_copy.iterrows():
        for j, cell in enumerate(row):
            if isinstance(cell, str) and re.search(r'GRADE|JOB CODE|Grade|Job Code', cell, re.IGNORECASE):
                start_row = i
                grade_col_idx = j
                break
        if start_row is not None:
            break
    
    # If we couldn't find grade by cell content, try column names
    if start_row is None:
        for j, col_name in enumerate(df_copy.columns):
            if isinstance(col_name, str) and re.search(r'GRADE|JOB CODE|Grade|Job Code', col_name, re.IGNORECASE):
                start_row = 0  # Start from the first data row
                grade_col_idx = j
                break
    
    if start_row is None:
        print(f"Could not find any row with GRADE or JOB CODE in {file_name}")
        return None
    
    # Extract data from the starting row onwards
    df = df.iloc[start_row+1:].reset_index(drop=True)
    
    # Get the column name for the grade column
    grade_col = df.columns[grade_col_idx] if grade_col_idx is not None else None
    
    # Identify columns for Annual salary
    annual_col = None
    annual_max_col = None
    
    # Search through column names for Annual
    for j, col_name in enumerate(df.columns):
        col_str = str(col_name).lower()
        if 'annual' in col_str or 'salary' in col_str:
            if annual_col is None:
                annual_col = col_name
            else:
                annual_max_col = col_name
    
    # If we couldn't find the annual column by name, search through the data
    if annual_col is None:
        # Look for columns that might contain salary data (numeric values)
        numeric_cols = []
        for col in df.columns:
            # Check if the column contains numeric-like values
            numeric_count = 0
            for val in df[col].astype(str).head(10):
                if re.search(r'\$?[\d,]+\.?\d*', str(val)):
                    numeric_count += 1
            
            if numeric_count >= 3:  # If at least 3 numeric values found
                numeric_cols.append(col)
        
        # If we found numeric columns, use the rightmost ones for annual
        if numeric_cols:
            annual_col = numeric_cols[-1]  # Last numeric column
            if len(numeric_cols) > 1:
                annual_max_col = numeric_cols[-2]  # Second to last numeric column
    
    if grade_col is None or annual_col is None:
        print(f"Could not identify required columns in {file_name}")
        return None
    
    # Create a new dataframe with required columns
    result_df = pd.DataFrame()
    
    # Extract grades
    result_df['grade'] = df[grade_col].astype(str)
    
    # Set term to 'annual' for all records
    result_df['term'] = 'annual'
    
    # Extract start_rate (min annual salary)
    result_df['start_rate'] = df[annual_col]
    
    # Extract end_rate (max annual salary) if available, otherwise use start_rate
    if annual_max_col is not None:
        result_df['end_rate'] = df[annual_max_col]
    else:
        result_df['end_rate'] = df[annual_col]
    
    # Add category column (file name without extension)
    result_df['category'] = os.path.splitext(file_name)[0]
    
    # Clean up data
    result_df = result_df.dropna(subset=['grade'])
    
    # Clean grade values (remove whitespace and nan values)
    result_df['grade'] = result_df['grade'].str.strip()
    result_df = result_df[result_df['grade'] != 'nan']
    result_df = result_df[result_df['grade'] != 'None']
    result_df = result_df[result_df['grade'] != '']
    
    # Convert dollar amounts to numeric
    for col in ['start_rate', 'end_rate']:
        if result_df[col].dtype == object:
            result_df[col] = result_df[col].astype(str)
            result_df[col] = result_df[col].str.replace('$', '', regex=True)
            result_df[col] = result_df[col].str.replace(',', '', regex=True)
            result_df[col] = pd.to_numeric(result_df[col], errors='coerce')
    
    return result_df

def main():
    # Define the folder path (update this to your actual path)
    folder_path = "/path/to/your/fabric/folder"
    
    # Define the list of files to process
    files_to_process = [
        "Non-Union Pharmacist.xlsx",
        "Non-Union Nurses.xlsx",
        "Non-Union Medical Technologist.xlsx",
        "Non-Union IT.xlsx",
        "Non-Union Doctors.xlsx",
        "Non-Union County Police.xlsx",
        "Non-Union Corporate.xlsx",
        "Non-Union Assistant State's Attorney.xlsx",
        "Non-Union Assistant Public Defender Supervisors.xlsx",
        # Add more files as needed
    ]
    
    # Alternatively, process all CSV and Excel files in the folder
    # files_to_process = []
    # for pattern in ["*.csv", "*.xlsx", "*.xls"]:
    #     files_to_process.extend([os.path.basename(file) for file in glob.glob(os.path.join(folder_path, pattern))])
    
    # Process the files
    result_df = process_salary_files(folder_path, files_to_process)
    
    # Output the result
    if not result_df.empty:
        print(f"Total records: {len(result_df)}")
        print(result_df.head())
        
        # Return the dataframe instead of saving to CSV
        return result_df
    else:
        print("No data was processed")
        return pd.DataFrame(columns=['grade', 'term', 'start_rate', 'end_rate', 'category'])

if __name__ == "__main__":
    main()
