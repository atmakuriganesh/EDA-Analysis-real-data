import os
import pandas as pd
import re
import glob

def process_salary_files(folder_path, file_list):
    """
    Process salary files from a folder based on a list of files.
    Scans all sheets in each file automatically.
    
    Args:
        folder_path (str): Path to the folder containing CSV/Excel files
        file_list (list): List of filenames to process
    
    Returns:
        pandas.DataFrame: Combined data with required columns
    """
    all_data = []
    
    for file_name in file_list:
        file_path = os.path.join(folder_path, file_name)
        
        # Determine the file extension
        file_ext = os.path.splitext(file_path)[1].lower()
        
        try:
            # For CSV files
            if file_ext == '.csv':
                df = pd.read_csv(file_path)
                processed_df = process_dataframe(df, file_name)
                if processed_df is not None:
                    all_data.append(processed_df)
            
            # For Excel files - try different engines
            elif file_ext in ['.xlsx', '.xls']:
                # Try different engines for Excel files
                engines = ['xlrd', 'openpyxl']
                success = False
                
                for engine in engines:
                    try:
                        if file_ext == '.xls' and engine == 'openpyxl':
                            # Skip openpyxl for .xls files
                            continue
                            
                        # Get all sheet names
                        excel_file = pd.ExcelFile(file_path, engine=engine)
                        sheet_names = excel_file.sheet_names
                        
                        for sheet_name in sheet_names:
                            try:
                                df = pd.read_excel(file_path, sheet_name=sheet_name, engine=engine)
                                processed_df = process_dataframe(df, f"{file_name}_{sheet_name}")
                                if processed_df is not None:
                                    all_data.append(processed_df)
                            except Exception as sheet_e:
                                continue
                        
                        # If we get here without errors, we've processed the file
                        success = True
                        break
                        
                    except Exception:
                        continue
                
                if not success:
                    print(f"Failed to process {file_name} with all available engines")
            else:
                print(f"Unsupported file format for {file_name}")
                continue
                
        except Exception:
            print(f"Error processing {file_name}")
    
    # Combine all data
    if all_data:
        # First, combine all processed data
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # Make sure to convert to numeric before aggregation
        combined_df['start_rate'] = pd.to_numeric(combined_df['start_rate'], errors='coerce')
        combined_df['end_rate'] = pd.to_numeric(combined_df['end_rate'], errors='coerce')
        
        # Drop rows with NaN values in start_rate or end_rate
        combined_df = combined_df.dropna(subset=['start_rate', 'end_rate'])
        
        # Aggregate by grade only to get min and max rates
        aggregated_df = combined_df.groupby(['grade']).agg({
            'start_rate': 'min',  # Minimum annual salary for the grade
            'end_rate': 'max',    # Maximum annual salary for the grade
            'category': 'first'   # Keep one category for reference
        }).reset_index()
        
        # Add term column with value 'annual'
        aggregated_df['term'] = 'annual'
        
        # Reorder columns
        aggregated_df = aggregated_df[['grade', 'term', 'start_rate', 'end_rate', 'category']]
        
        return aggregated_df
    else:
        return pd.DataFrame(columns=['grade', 'term', 'start_rate', 'end_rate', 'category'])

def process_dataframe(df, file_name):
    """
    Process a single dataframe to extract the required information.
    
    Args:
        df (pandas.DataFrame): The dataframe to process
        file_name (str): Name of the file/sheet for category
    
    Returns:
        pandas.DataFrame: Processed dataframe with required columns
    """
    # Skip empty dataframes
    if df.empty:
        return None
    
    # Find the grade column
    grade_col = None
    for col in df.columns:
        col_str = str(col).lower()
        if 'grade' in col_str or 'job code' in col_str or 'job' in col_str:
            grade_col = col
            break
    
    # If grade column not found by name, search in data
    if grade_col is None:
        # Look for "GRADE" or "JOB CODE" in the data
        for i, row in df.iterrows():
            for j, val in enumerate(row):
                if isinstance(val, str) and re.search(r'GRADE|JOB CODE', val, re.IGNORECASE):
                    # Grade column is likely this column or the next
                    if j < len(df.columns) - 1:
                        # Try to use the next column where actual grade values appear
                        grade_col = df.columns[j+1]
                    else:
                        grade_col = df.columns[j]
                    # Skip to the next row to start reading data
                    df = df.iloc[i+1:].reset_index(drop=True)
                    break
            if grade_col is not None:
                break
    
    # If still no grade column, look for a column with grade-like values
    if grade_col is None:
        for col in df.columns[:3]:  # Check first few columns, grades usually appear early
            sample = df[col].astype(str).head(10)
            if sample.str.match(r'^[A-Za-z0-9]+$').any():
                grade_col = col
                break
    
    # Find annual salary column
    annual_col = None
    for col in df.columns:
        col_str = str(col).lower()
        if 'annual' in col_str or 'salary' in col_str:
            annual_col = col
            break
    
    # If no annual column found by name, look for columns with dollar values or large numbers
    if annual_col is None:
        for col in df.columns:
            # Skip if this is the grade column
            if col == grade_col:
                continue
                
            sample = df[col].astype(str).head(10)
            if sample.str.contains(r'\$|\d{4,}').any():
                annual_col = col
                break
    
    # If we couldn't identify required columns, return None
    if grade_col is None or annual_col is None:
        return None
    
    # Create result dataframe
    result_df = pd.DataFrame()
    
    # Extract grade values
    result_df['grade'] = df[grade_col].astype(str)
    
    # Always set term to 'annual'
    result_df['term'] = 'annual'
    
    # Use the annual column for both start_rate and end_rate initially
    # The aggregation later will find min/max values per grade
    result_df['start_rate'] = df[annual_col]
    result_df['end_rate'] = df[annual_col]
    
    # Add category from filename
    result_df['category'] = os.path.splitext(file_name)[0]
    
    # Clean up data
    result_df = result_df.dropna(subset=['grade'])
    result_df['grade'] = result_df['grade'].str.strip()
    
    # Remove rows with empty or invalid grades
    result_df = result_df[result_df['grade'] != '']
    result_df = result_df[result_df['grade'] != 'nan']
    result_df = result_df[result_df['grade'] != 'None']
    
    # Handle numeric values: remove $ and commas, convert to float
    for col in ['start_rate', 'end_rate']:
        result_df[col] = result_df[col].astype(str).str.replace('$', '', regex=True)
        result_df[col] = result_df[col].str.replace(',', '', regex=True)
        result_df[col] = pd.to_numeric(result_df[col], errors='coerce')
    
    return result_df

def main():
    # Define the folder path (update this to your actual path)
    folder_path = "/path/to/your/fabric/folder"
    
    # Define the list of files to process
    files_to_process = [
        "Non-Union Pharmacist.xlsx",
        "Non-Union Nurses.xlsx",
        "Non-Union Medical Technologist.xlsx",
        "Non-Union IT.xlsx",
        "Non-Union Doctors.xlsx",
        "Non-Union County Police.xlsx",
        "Non-Union Corporate.xlsx",
        "Non-Union Assistant State's Attorney.xlsx",
        "Non-Union Assistant Public Defender Supervisors.xlsx",
        # Add more files as needed
    ]
    
    # Process the files
    result_df = process_salary_files(folder_path, files_to_process)
    
    # Return the dataframe
    if not result_df.empty:
        return result_df
    else:
        return pd.DataFrame(columns=['grade', 'term', 'start_rate', 'end_rate', 'category'])

if __name__ == "__main__":
    main()
